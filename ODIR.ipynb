{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCKLrdh1IarWA0qae14HMP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shachin4502/Ocular_disease_intelligent_recognition/blob/main/ODIR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pstJTFFkR4vd",
        "outputId": "0ea6fae3-d4cf-408c-ca45-9bd59c526242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Mounted at /content/gdrive\n",
            " animals  'Colab Notebooks'  'My Drive'\t\t\t nm_project   TTGD\n",
            " ani.zip   index.html\t     'name of the animals.txt'\t output\n",
            "/content/gdrive/My Drive/nm_project\n"
          ]
        }
      ],
      "source": [
        "#mount drive\n",
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "\n",
        "# list the contents of /mydrive\n",
        "!ls /mydrive\n",
        "\n",
        "%cd /mydrive/nm_project"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras. preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "NYw5ytvvZmpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "YVd7JBldhe3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory(\"/content/gdrive/MyDrive/nm_project/output/train\",target_size = (224,224),batch_size = 64,class_mode = \"categorical\")\n",
        "test_set = test_datagen.flow_from_directory(\"/content/gdrive/MyDrive/nm_project/output/val\",target_size = (224,224),batch_size = 64,class_mode = \"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcwYSQU_i3W9",
        "outputId": "08be21ee-cfb5-4df6-f586-9a25ccdb3827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3304 images belonging to 4 classes.\n",
            "Found 832 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG19 = VGG19(input_shape=(224,224,3),weights = 'imagenet',include_top=False)"
      ],
      "metadata": {
        "id": "_3Cp8VKti3gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in VGG19.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "IeTwIP1zi3kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(VGG19.output)"
      ],
      "metadata": {
        "id": "qjceFkjilyNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = Dense(4,activation = 'softmax')(x)\n",
        "model = Model(inputs = VGG19.input,outputs = prediction )"
      ],
      "metadata": {
        "id": "q5jvQKiYlyXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd1jLdPtlyaj",
        "outputId": "28aaa72a-097b-4d53-e287-15e629d42cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 100356    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,124,740\n",
            "Trainable params: 100,356\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "q3uzHcJQmiXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_set,validation_data = test_set ,epochs = 50,steps_per_epoch= len(training_set),validation_steps=len(test_set))"
      ],
      "metadata": {
        "id": "woQu8n6omibE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe1d916-0b00-41ad-dbce-8aabafdff197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "52/52 [==============================] - 539s 10s/step - loss: 1.2307 - accuracy: 0.5599 - val_loss: 0.6300 - val_accuracy: 0.7308\n",
            "Epoch 2/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.6526 - accuracy: 0.7424 - val_loss: 0.7523 - val_accuracy: 0.7031\n",
            "Epoch 3/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.5384 - accuracy: 0.7878 - val_loss: 0.5581 - val_accuracy: 0.7849\n",
            "Epoch 4/50\n",
            "52/52 [==============================] - 78s 2s/step - loss: 0.4815 - accuracy: 0.8054 - val_loss: 0.4800 - val_accuracy: 0.8089\n",
            "Epoch 5/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.4465 - accuracy: 0.8299 - val_loss: 0.5060 - val_accuracy: 0.7981\n",
            "Epoch 6/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.4304 - accuracy: 0.8357 - val_loss: 0.6113 - val_accuracy: 0.7620\n",
            "Epoch 7/50\n",
            "52/52 [==============================] - 81s 2s/step - loss: 0.4247 - accuracy: 0.8335 - val_loss: 0.4489 - val_accuracy: 0.8209\n",
            "Epoch 8/50\n",
            "52/52 [==============================] - 81s 2s/step - loss: 0.4483 - accuracy: 0.8235 - val_loss: 0.5558 - val_accuracy: 0.7584\n",
            "Epoch 9/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.4232 - accuracy: 0.8287 - val_loss: 0.5613 - val_accuracy: 0.7632\n",
            "Epoch 10/50\n",
            "52/52 [==============================] - 81s 2s/step - loss: 0.4366 - accuracy: 0.8248 - val_loss: 0.5815 - val_accuracy: 0.7548\n",
            "Epoch 11/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.3880 - accuracy: 0.8478 - val_loss: 0.4094 - val_accuracy: 0.8450\n",
            "Epoch 12/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.3939 - accuracy: 0.8438 - val_loss: 0.5900 - val_accuracy: 0.7752\n",
            "Epoch 13/50\n",
            "52/52 [==============================] - 81s 2s/step - loss: 0.3596 - accuracy: 0.8568 - val_loss: 0.4177 - val_accuracy: 0.8486\n",
            "Epoch 14/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3312 - accuracy: 0.8708 - val_loss: 0.5290 - val_accuracy: 0.7969\n",
            "Epoch 15/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3802 - accuracy: 0.8487 - val_loss: 0.8004 - val_accuracy: 0.7055\n",
            "Epoch 16/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.3911 - accuracy: 0.8414 - val_loss: 0.5417 - val_accuracy: 0.7825\n",
            "Epoch 17/50\n",
            "52/52 [==============================] - 80s 2s/step - loss: 0.3432 - accuracy: 0.8608 - val_loss: 0.4378 - val_accuracy: 0.8389\n",
            "Epoch 18/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3499 - accuracy: 0.8565 - val_loss: 0.4351 - val_accuracy: 0.8438\n",
            "Epoch 19/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3880 - accuracy: 0.8453 - val_loss: 0.7362 - val_accuracy: 0.7260\n",
            "Epoch 20/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.4035 - accuracy: 0.8387 - val_loss: 0.4221 - val_accuracy: 0.8438\n",
            "Epoch 21/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3604 - accuracy: 0.8526 - val_loss: 0.4199 - val_accuracy: 0.8474\n",
            "Epoch 22/50\n",
            "52/52 [==============================] - 78s 2s/step - loss: 0.3364 - accuracy: 0.8632 - val_loss: 0.6958 - val_accuracy: 0.7344\n",
            "Epoch 23/50\n",
            "52/52 [==============================] - 78s 1s/step - loss: 0.3925 - accuracy: 0.8475 - val_loss: 0.3440 - val_accuracy: 0.8582\n",
            "Epoch 24/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3359 - accuracy: 0.8662 - val_loss: 0.4527 - val_accuracy: 0.8233\n",
            "Epoch 25/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3342 - accuracy: 0.8650 - val_loss: 0.6545 - val_accuracy: 0.7680\n",
            "Epoch 26/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.3068 - accuracy: 0.8777 - val_loss: 0.5172 - val_accuracy: 0.8137\n",
            "Epoch 27/50\n",
            "52/52 [==============================] - 79s 2s/step - loss: 0.2961 - accuracy: 0.8832 - val_loss: 0.3964 - val_accuracy: 0.8678\n",
            "Epoch 28/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.3002 - accuracy: 0.8801 - val_loss: 0.3869 - val_accuracy: 0.8762\n",
            "Epoch 29/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.3158 - accuracy: 0.8771 - val_loss: 0.5637 - val_accuracy: 0.8089\n",
            "Epoch 30/50\n",
            "52/52 [==============================] - 78s 1s/step - loss: 0.3041 - accuracy: 0.8798 - val_loss: 0.3876 - val_accuracy: 0.8606\n",
            "Epoch 31/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.3003 - accuracy: 0.8792 - val_loss: 0.4003 - val_accuracy: 0.8630\n",
            "Epoch 32/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.2961 - accuracy: 0.8817 - val_loss: 0.5904 - val_accuracy: 0.7800\n",
            "Epoch 33/50\n",
            "52/52 [==============================] - 78s 1s/step - loss: 0.2762 - accuracy: 0.8865 - val_loss: 0.3759 - val_accuracy: 0.8702\n",
            "Epoch 34/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.3359 - accuracy: 0.8677 - val_loss: 0.6410 - val_accuracy: 0.7825\n",
            "Epoch 35/50\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.3672 - accuracy: 0.8571 - val_loss: 0.5687 - val_accuracy: 0.7993\n",
            "Epoch 36/50\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.3053 - accuracy: 0.8750 - val_loss: 0.4013 - val_accuracy: 0.8510\n",
            "Epoch 37/50\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.2798 - accuracy: 0.8929 - val_loss: 0.6295 - val_accuracy: 0.7728\n",
            "Epoch 38/50\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.2717 - accuracy: 0.8929 - val_loss: 0.4212 - val_accuracy: 0.8377\n",
            "Epoch 39/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.2916 - accuracy: 0.8835 - val_loss: 0.6352 - val_accuracy: 0.7861\n",
            "Epoch 40/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.2483 - accuracy: 0.9056 - val_loss: 0.4044 - val_accuracy: 0.8570\n",
            "Epoch 41/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.2785 - accuracy: 0.8932 - val_loss: 0.4167 - val_accuracy: 0.8570\n",
            "Epoch 42/50\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.2587 - accuracy: 0.8986 - val_loss: 0.3373 - val_accuracy: 0.8858\n",
            "Epoch 43/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.2650 - accuracy: 0.8947 - val_loss: 0.4708 - val_accuracy: 0.8317\n",
            "Epoch 44/50\n",
            "52/52 [==============================] - 77s 1s/step - loss: 0.2620 - accuracy: 0.8932 - val_loss: 0.4682 - val_accuracy: 0.8341\n",
            "Epoch 45/50\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.3118 - accuracy: 0.8811 - val_loss: 0.4435 - val_accuracy: 0.8438\n",
            "Epoch 46/50\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.2544 - accuracy: 0.9031 - val_loss: 0.4041 - val_accuracy: 0.8642\n",
            "Epoch 47/50\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.2483 - accuracy: 0.9059 - val_loss: 0.3808 - val_accuracy: 0.8786\n",
            "Epoch 48/50\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.2678 - accuracy: 0.8944 - val_loss: 0.4058 - val_accuracy: 0.8642\n",
            "Epoch 49/50\n",
            "52/52 [==============================] - 75s 1s/step - loss: 0.2713 - accuracy: 0.8916 - val_loss: 0.3450 - val_accuracy: 0.8726\n",
            "Epoch 50/50\n",
            "52/52 [==============================] - 76s 1s/step - loss: 0.2353 - accuracy: 0.9053 - val_loss: 0.5167 - val_accuracy: 0.8293\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6c40184b20>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('odir.h5')"
      ],
      "metadata": {
        "id": "4cW2bSof0Qev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"/content/gdrive/MyDrive/nm_project/odir.h5\")"
      ],
      "metadata": {
        "id": "g1806KnIKjX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img(\"/content/gdrive/MyDrive/nm_project/output/val/normal/1060_left.jpg\",target_size=(224,224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis= 0)\n",
        "preds=model.predict(x)\n",
        "pred=np.argmax(preds,axis =1)\n",
        "index = ['cataract','Diabetic_retinopathy','glaucoma','normal']\n",
        "result = str(index[pred[0]])\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "vUvuUfWhN5C3",
        "outputId": "58d67b5a-d7ca-47f0-f642-95d46c8bcced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'normal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}